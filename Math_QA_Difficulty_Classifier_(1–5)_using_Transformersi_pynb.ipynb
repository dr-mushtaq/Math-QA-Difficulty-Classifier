{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6EFgbFXOBQ0ielh+j5cv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dr-mushtaq/Math-QA-Difficulty-Classifier/blob/main/Math_QA_Difficulty_Classifier_(1%E2%80%935)_using_Transformersi_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîß Step-by-Step Implementation Plan**"
      ],
      "metadata": {
        "id": "j2m8Vu5gxR3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÅ 1. Dataset Preparation\n",
        "\n",
        "‚û§ **Data Sources**\n",
        "Train: hendrycks_math_train.csv\n",
        "\n",
        "Test: hendrycks_math_test.csv\n",
        "\n",
        "‚û§ **Tasks:**\n",
        "\n",
        "Load both CSVs using pandas\n",
        "\n",
        "Inspect and clean the data (e.g., missing values)\n",
        "\n",
        "Combine question + answer as input text\n",
        "\n",
        "Difficulty is the label (1‚Äì5)"
      ],
      "metadata": {
        "id": "UqvqXYkQxY8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß† 2. Modeling Approach**\n",
        "\n",
        "We‚Äôll treat this as a text classification task, using transformer-based models like:\n",
        "\n",
        "BERT, RoBERTa, or DeBERTa (for accuracy)\n",
        "\n",
        "DistilBERT (for speed and low compute environments)\n",
        "\n",
        "Fine-tune using HuggingFace Transformers"
      ],
      "metadata": {
        "id": "EPW33caxxrsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLLFPXnDxNQt"
      },
      "outputs": [],
      "source": [
        "‚û§ Input:\n",
        "\n",
        "plaintext\n",
        "Input: \"Q: <question text> A: <answer text>\"\n",
        "Output: Class label (1 to 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß™ 3. Evaluation Metric**\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Weighted F1-score (due to potential class imbalance)\n",
        "\n",
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "2FYeoQrOx5Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üì¶ 4. Required Libraries**"
      ],
      "metadata": {
        "id": "1vAHy4WLx92Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets scikit-learn pandas torch\n"
      ],
      "metadata": {
        "id": "FgrFIw6SyBzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚úÖ Example Python Code (Core)**"
      ],
      "metadata": {
        "id": "opstISHlyVfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"hendrycks_math_train.csv\")\n",
        "df_test = pd.read_csv(\"hendrycks_math_test.csv\")\n",
        "\n",
        "# Combine question and answer\n",
        "df[\"text\"] = \"Q: \" + df[\"question\"] + \" A: \" + df[\"answer\"]\n",
        "df_test[\"text\"] = \"Q: \" + df_test[\"question\"] + \" A: \" + df_test[\"answer\"]\n",
        "\n",
        "# Prepare train/val split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"], df[\"difficulty\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(df_test[\"text\"]), truncation=True, padding=True)\n",
        "\n",
        "# Dataset wrapper\n",
        "class MathDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels if labels is not None else None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx] - 1)  # make 0-indexed\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "train_dataset = MathDataset(train_encodings, train_labels.tolist())\n",
        "val_dataset = MathDataset(val_encodings, val_labels.tolist())\n",
        "\n",
        "# Model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
        "\n",
        "# Training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Evaluation\n",
        "preds = trainer.predict(val_dataset)\n",
        "y_pred = preds.predictions.argmax(-1) + 1  # return to 1-indexed\n",
        "y_true = val_labels.values\n",
        "\n",
        "print(classification_report(y_true, y_pred, digits=3))\n"
      ],
      "metadata": {
        "id": "VUvcNlhayZqo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}